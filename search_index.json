[["index.html", "Using Itrax Data in R Preface", " Using Itrax Data in R Thomas Bishop 2020-12-17 Preface Itrax core scanners (manufactured by Cox Analytical Systems, Sweden) are used in palaeoceanography, palaeolimnological, geological and other “down-core” studies of sedimentary core material. The multi-sensory data can include radiography, optical images, magnetic susceptibility, but most importantly energy-dispersive x-ray florescence (ED-XRF) measurements of elemental abundance. The data can be harder to work with compared to some other palaeoenvironmental techniques because: Very large quantities of data are produced. ED-XRF measurements can be made every 100-200 μm, so for long core sections, these datasets are large. Simple line-graphs can become problematic, and multivariate analysis can become unworkable on some software. Images can be very large and need correct alignment. Combining them with line-graphs or other images can be troublesome. ED-XRF elemental data is compositional, but dimensionless (they do not have units attached e.g. [ppm]). This can make the use of traditional statistical tools and tests problematic. This guide comes from a series of seminars offered to users of the Itrax core scanner at The University of Manchester Geography Laboratories in 2020. "],["the-itraxr-package.html", "0.1 The itraxR Package", " 0.1 The itraxR Package The itraxR package offers a range of convenience functions for working with Itrax data. The book mostly uses the functions in this package, but the source code is available and fully commented, so is easy to as a basis for other work. The package and code are available from github.com/tombishop1/itraxR. "],["prerequisites.html", "0.2 Prerequisites", " 0.2 Prerequisites This guide assumes a basic knowledge of R and the tidyverse, including data types, assignments, and pipes. It also assumes a background knowledge of the core scanner and the nature of the data it produces; see Croudace et al. (2019) and references therein. Some of the sections on data analysis assume some knowledge of compositional data analysis. References "],["example-data.html", "0.3 Example Data", " 0.3 Example Data All of these examples given in this book are from Piston core CD166/19, which was recovered from the Agadir Basin during the RRS Charles Darwin expedition CD166 in 2004 (Wynn and Cronin (2005)). The core site is located at 31°31’ N, 17°11.77’ W at a water depth of 4502 m. The coring operation recovered 4.3 m of sediment composed of hemipelagite and turbidites. The hemipelagic sediments range from cream-brown carbonate-rich marl/ooze to red-brown clays. The turbidites include siliciclastic, volcaniclastic and calcareous sediments. The split core sections were analysed using the Cox Analytical Systems Itrax core scanner at the British Ocean Sediment Core Research Facility, National Oceanography Centre (Southampton, UK). The split core surfaces were cleaned and loaded to the core scanner along with a radiographic reference sample (Francus, Kanamaru, and Fortin (2015)) and a colour card. The cores were first scanned to measure the sample surface height and to obtain optical images. The core sections were then covered with Mylar film to reduce sample desiccation during XRF scanning and x-radiography. XRF data were acquired using a molybdenum X-ray tube set at 30 kV and 30 mA with a dwell time of 30 seconds and a step size of 1 mm. X-radiographs were acquired with voltage and current set to 55 kV and 50 mA, respectively, and dwell time set to 500 ms. Step size for the x-radiography was set to 200 µm. Two replicate XRF scans were also performed for each of the three core sections that make up this core. The XRF settings for the replicates were kept consistent with those of the main XRF scan. The interval selected for the replicate scans ranged from 10 cm to 15 cm of the the total sample length. All raw XRF raw data were reprocessed using the QSpec spectral analysis software to optimise peak fitting. The data can be downloaded from the Github pages that form the source for this document, available at github.com/tombishop1/itraxBook. References "],["utility-data.html", "0.4 Utility Data", " 0.4 Utility Data It is often useful to have a list of symbols used to represent elements for various subsetting functions. This can be extracted from the example data included with the package periodicTable as follows. The vector called elementslist will be referred to elsewhere in this book. data(periodicTable) elementsList &lt;- periodicTable$symb rm(periodicTable) "],["intro.html", "Chapter 1 Data Structure", " Chapter 1 Data Structure The Itrax core scanner is a multi-sensor device, with separate data outputs for different measurements and uses. They are described in the following sections. Note that your data may not contain all of these objects, depending on the exact scanner, configuration, or data repository you use. The folder structure may vary between operators, but typically there will be a folder for each scan section, and each will contain the data described in the following sections. Note that where radiographs and XRF data have been acquired using different step-sizes (measurement intervals), the operator will create seperate scan sections (folders) for the x-radiograph and XRF measurement. This is because a scan section can only have a single fixed step-size. For example, it is not uncommon for users to require an step-size of 200 μm for the x-radiograph, but only 1 mm for the XRF measurement. "],["metadata.html", "1.1 Metadata", " 1.1 Metadata Every scan folder has a document.txt file that contains information about the parameters of the scan. For example, it contains the current and voltage settings used for the x-ray tube, the step size, and the start and stop positions of the scan. It is a text file, although the formatting can be inconsistently rendered depending on the text editor used. Sometimes this information is required to process other parts of the data, and as such it is an important part of the overall data package. "],["xrf-data.html", "1.2 XRF Data", " 1.2 XRF Data The XRF data can be split into two groups — “raw” and “processed” data. The raw data is contained in a separate folder called XRF data, and consists of a single file, beginning with L000000.spe and incrementing sequentially. This file can be read using a text editor and is tab-delimited. The first part is a header, containing metadata information. The second part is a table of all the channels of the detector and the corresponding count for each channel. Increasing channel numbers represent increasing energy, but some thought needs to be given to calibrating channels into an energy — this step is usually performed using specialist software. In addition, a file called sumspectra.spe is often included in the root directory; this is simply the sum of all the *.spe files in the XRF data directory, and is sometimes useful in processing the data. Processed data comes from the Q-Spec software (Cox Analytical Systems, Sweden) provided with the machine. Its function is to process the spectral data files (*.spe) into peak-areas for each element of interest by fitting a model to the data. The model needs some user input and intervention to optimise it, and the quality of the model can be assessed using a number of diagnostic parameters, the most important being the root-mean-squared-error (RMSE). The Q-Spec software can also perform some quantitative calibration of the data, although this is a less typical use-case. Often the operator will include a file that contains all of the settings used by Q-Spec to translate the raw data files into the peak area output file — this file will have the extension *.dfl and will often simply be called settings.dfl. The processed elemental data comes in the form of a text file comprising of a tab-delimited table, with a single row for each measurement step, and a column for parameters including individual element peak areas in counts (n) or intensities (n/mA). The data files commonly have names like result.txt or Results.txt, but may have been subsequently renamed. These are the ED-XRF data most commonly worked with by analysts. "],["optical-images.html", "1.3 Optical Images", " 1.3 Optical Images The scanner collects good quality optical images that have consistent lighting and because they are line-scan images, they do not suffer from optical distortions. Medium resolution images are usually included in all scan section folders (typically optical.tif), and optional high-resolution images are often included by operators elsewhere. High resolution images are typically supplied as both 8-bit and 16-bit images, and are usually hundreds of megabytes in size. Although the brightness of the lighting in the scanner is adjustable, images sometimes need to be brightened and/or have the contrast adjusted. This can be performed in desktop publishing software (e.g. Adobe Photoshop, Corel Photo-Draw), but it is easiest to use the open-source scientific image analysis software imageJ (NIH, USA). By including an appropriate colour reference card in the scan the image can be calibrated, although it is often desirable to increase the contrast and gamma to elucidate features of the core. The photograph is always of the entire length of the bed scanned, rather than cropped to the limits of an individual scan section. If multiple scan sections are placed on the bed and are scanned together, it will include all of the scanned sections. The image needs to be cropped using the metadata for the relevant scan section; this process is covered in later chapters. "],["radiographic-images.html", "1.4 Radiographic Images", " 1.4 Radiographic Images The scanner has an x-radiographic line array capable of producing good-quality x-radiographs of the cores. The scan data can be split into two parts — “raw” and “processed” data. The raw data (usually radiograph.raw) is a tab-delimited text file containing a matrix of greyscale values. Each column represents a single step (measurement interval, often set to between 50 and 200 μm), and each row represents a single pixel on the line array. The pixel spacing is around 20 μm. Note that the raw radiographic data contains pixels at the extremes that are outside of the coverage of the x-ray beam — these are obviously useless and need to be cropped. The processed image (radiograph.tif) has a lower resolution than the raw data. This is because the pixels must be square, and so the pixels are down-sampled to fit with the step-size of the scan. Thus, if the step-size was 200 μm, each pixel will be 200 x 200 μm, whereas the raw data will have rectangular pixels with dimensions of 20 x 200 μm. The data at the extremes of the radiograph are always cropped, so the radiograph has a coverage of around 13 mm of thw width of the core. Like the optical image, the radiograph often requires contrast and brightness adjustments, and these are easiest to perform in imageJ. With the inclusion of a suitable density standard, some relative or, where “u-channels” are used, absolute density calibration can be performed using these data; see Francus, Kanamaru, and Fortin (2015) for more. References "],["magnetic-susceptability.html", "1.5 Magnetic Susceptability", " 1.5 Magnetic Susceptability Some scanners include a Bartington MS2E surface sensor, but the example dataset supplied here does not have magnetic susceptability data collected from an Itrax core scanner. "],["importing.html", "Chapter 2 Importing Data", " Chapter 2 Importing Data All of the Itrax data is in either text-format or “tagged image format” (*.tif). Although this means it is easily read by the various import functions available in R, it still needs considerable cleaning and wrangling to get it to a point where it is usable for most analyses. There are three possible approaches to this task: Use existing functions published in the itraxR package available from github.com/tombishop1/itraxR. These are at an early stage and functionality might be broken, but are largely convenience functions for wrangling and analysing Itrax data. It is easy to install the package directly from Github using remotes::install_github(\"tombishop1/itraxR\"). Work in base R to wrangle the data. This is perfectly achievable, and much of the current itraxR functionality was originally written this way. Work in the tidyverse family of packages and style. For data wrangling tasks, this approach can result in simpler and more resilient code. In this guide examples will be given using the functions provided in itraxR, but the processes used in those functions will be explained, and the code used in those functions is fully commented so can be modified to suit particular needs. "],["metadata-1.html", "2.1 Metadata", " 2.1 Metadata The scan metadata file document.txt can be quickly parsed using itraxR::itrax_meta(). The output is a dataframe from which the individual components can be easily accessed through subsetting functions; for example as.numeric(itrax_meta()[6:7, 2]) would return a numeric vector of the start and end position of a scan. itrax_meta(&quot;CD166_19_S1/CD166_19_S1/document.txt&quot;) ## Parameter Value Unit ## 1 Sample name CD166_19_S1 str ## 2 Section name CD166_19_S1 str ## 3 Aquisition date 22/9/2020 dd/mm/yyyy ## 4 Operator name MC str ## 5 Tube Mo element ## 6 Start coordinate 31.5 mm ## 7 Stop coordinate 1314.1 mm ## 8 Step size 1000 microns ## 9 Optical Start 0.5 mm ## 10 Optical End 1401.3 mm ## 11 Optical step size 0.188 mm ## 12 Rad. voltage 55 kV ## 13 Rad. current 50 mA ## 14 Rad. exposure 0 ms ## 15 line camera signal level 323154 at 25 ms ## 16 XRF ON ON/OFF ## 17 XRF voltage 30 kV ## 18 XRF current 30 mA ## 19 XRF exp. time 15 seconds ## 20 Start temperature \\xb0C ## 21 Stop temperature \\xb0C ## 22 Start humidity % ## 23 Stop humidity % ## 24 Start vacuum -95.0 kPa ## 25 Stop vacuum -94.8 kPa "],["xrf-data-1.html", "2.2 XRF Data", " 2.2 XRF Data 2.2.1 Processed Data This is the data most commonly used in analysis and it can be quickly imported using itraxR::itrax_import(). Note that, like for the example data, it is possible to have more than one processed data file. Typically cores have at least two, one created at the time of the scan based on settings for a single point near the top of the sequence, and another from a holistic re-analysis of the sequence. itrax_import(&quot;CD166_19_S1/CD166_19_S1/Results.txt&quot;, depth = 0) %&gt;% head() ## [90m# A tibble: 6 x 43[39m ## depth MSE cps validity Al Si P S Cl Ar K Ca ## [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;lgl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m ## [90m1[39m 1 1.41 [4m3[24m[4m4[24m525 TRUE 76 275 0 10 [4m1[24m318 604 [4m2[24m565 [4m1[24m[4m1[24m[4m2[24m734 ## [90m2[39m 2 1.57 [4m3[24m[4m8[24m370 TRUE 57 306 0 0 [4m1[24m513 595 [4m2[24m628 [4m1[24m[4m4[24m[4m4[24m287 ## [90m3[39m 3 1.55 [4m3[24m[4m9[24m796 TRUE 74 330 0 32 [4m1[24m470 506 [4m2[24m378 [4m1[24m[4m6[24m[4m2[24m938 ## [90m4[39m 4 1.41 [4m4[24m[4m0[24m022 TRUE 26 206 0 21 [4m1[24m312 555 [4m2[24m265 [4m1[24m[4m5[24m[4m3[24m194 ## [90m5[39m 5 1.41 [4m4[24m[4m1[24m973 TRUE 53 233 0 37 [4m1[24m740 591 [4m2[24m947 [4m1[24m[4m3[24m[4m5[24m879 ## [90m6[39m 6 1.36 [4m4[24m[4m1[24m268 TRUE 27 347 0 28 [4m1[24m576 504 [4m3[24m179 [4m1[24m[4m3[24m[4m2[24m183 ## [90m# … with 31 more variables: Sc [3m[90m&lt;dbl&gt;[90m[23m, Ti [3m[90m&lt;dbl&gt;[90m[23m, V [3m[90m&lt;dbl&gt;[90m[23m, Cr [3m[90m&lt;dbl&gt;[90m[23m, Mn [3m[90m&lt;dbl&gt;[90m[23m,[39m ## [90m# Fe [3m[90m&lt;dbl&gt;[90m[23m, Ni [3m[90m&lt;dbl&gt;[90m[23m, Cu [3m[90m&lt;dbl&gt;[90m[23m, Zn [3m[90m&lt;dbl&gt;[90m[23m, Ga [3m[90m&lt;dbl&gt;[90m[23m, Ge [3m[90m&lt;dbl&gt;[90m[23m, Br [3m[90m&lt;dbl&gt;[90m[23m,[39m ## [90m# Rb [3m[90m&lt;dbl&gt;[90m[23m, Sr [3m[90m&lt;dbl&gt;[90m[23m, Y [3m[90m&lt;dbl&gt;[90m[23m, Zr [3m[90m&lt;dbl&gt;[90m[23m, Pd [3m[90m&lt;dbl&gt;[90m[23m, Cd [3m[90m&lt;dbl&gt;[90m[23m, I [3m[90m&lt;dbl&gt;[90m[23m,[39m ## [90m# Cs [3m[90m&lt;dbl&gt;[90m[23m, Ba [3m[90m&lt;dbl&gt;[90m[23m, Nd [3m[90m&lt;dbl&gt;[90m[23m, Sm [3m[90m&lt;dbl&gt;[90m[23m, Yb [3m[90m&lt;dbl&gt;[90m[23m, Ta [3m[90m&lt;dbl&gt;[90m[23m, W [3m[90m&lt;dbl&gt;[90m[23m,[39m ## [90m# Pb [3m[90m&lt;dbl&gt;[90m[23m, Bi [3m[90m&lt;dbl&gt;[90m[23m, `Mo inc` [3m[90m&lt;dbl&gt;[90m[23m, `Mo coh` [3m[90m&lt;dbl&gt;[90m[23m, position [3m[90m&lt;dbl&gt;[90m[23m[39m 2.2.2 Joining XRF Data Often a core (sometimes referred to as a drive) is comprised of a sequence of individual sections, which may or may not be overlapping. Often we will want to integrate them into a continuous dataset for analytical purposes. When joining cores that do not overlap, this process is trivial — the data might simply appended in order of depth, and a new column is added with the identity of the original core section. Where overlapping cores are present, there can be multiple measurements at a single depth (on different cores). In these cases not only will the individual measurements need to be re-ordered by depth, but an additional variable should be created that can be used in combination or alone to uniquely identify each measurement. The code below does this by creating an additional variable called label, with the name of the original core given in the named list. mylist &lt;- list(core1 = core1, core2 = core2) df &lt;- lapply(names(mylist), function(i) within(mylist[[i]], {label &lt;- i})) %&gt;% bind_rows() %&gt;% arrange(depth) This process can be simplified using itraxR::itrax_join(), for example: # import the core sections CD166_19_S1 &lt;- itrax_import(&quot;CD166_19_S1/CD166_19_S1/Results.txt&quot;, depth_top = 0) CD166_19_S2 &lt;- itrax_import(&quot;CD166_19_S2/CD166_19_S2/Results.txt&quot;, depth_top = max(CD166_19_S1$depth)) CD166_19_S3 &lt;- itrax_import(&quot;CD166_19_S3/CD166_19_S3/Results.txt&quot;, depth_top = max(CD166_19_S2$depth)) #join them together CD166_19 &lt;- itrax_join(list(S1 = CD166_19_S1, S2 = CD166_19_S2, S3 = CD166_19_S3)) dim(CD166_19) ## [1] 4206 44 rm(CD166_19_S1, CD166_19_S2, CD166_19_S3) 2.2.3 Raw Data Sometimes it is useful to work with raw data rather than the calculated intensity data from the Q-Spec software. In this case, the raw data can be read directly from the individual files in the relevant directory. For individual measurements this is fairly trivial, although it must be considered that the data output is not calibrated to an energy and the data are in counts, not intensities. If the entire scan is read, some mechanism to iterate through the individual data files, adding them to a structured data object with relevant metadata (positions, for example) is required. "],["optical-images-1.html", "2.3 Optical Images", " 2.3 Optical Images In order to make the images usable for plotting alongside other data, they need to be cropped to the scanned area and referenced to the position or a depth variable. The initial crop can be supressed using trim = FALSE if the whole image is desired. Images in R are read in as a matrix with 3 dimensions (length, width, and the three colours). The data can be imported using itraxR::itrax_image(). This function can produce a basic diagram (shown in subsequent section), but here we focus on the structure of the imported object. $image is a three dimensional array, the first two dimensions are the length of the core and the width, respectively. Those two dimensions have \"dimnames\" (rownames() and colnames() respectively). For the rownames(), this is an interpolated position, in mm, and for the colnames() this is the width in mm, and always begins at 0. The last dimension always has a length of three, and comprises of the red, green and blue values for each of the pixels. $meta is a table containing selected data from the scan metadata relevant to the image. itrax_image(file = &quot;CD166_19_S1/CD166_19_S1/optical.tif&quot;, meta = &quot;CD166_19_S1/CD166_19_S1/document.txt&quot;, trim = FALSE) %&gt;% str() ## List of 2 ## $ image: num [1:7452, 1:524, 1:3] 0.0706 0.0706 0.0706 0.0784 0.0784 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 3 ## .. ..$ : chr [1:7452] &quot;0.5&quot; &quot;0.688001610522078&quot; &quot;0.876003221044155&quot; &quot;1.06400483156623&quot; ... ## .. ..$ : chr [1:524] &quot;0&quot; &quot;0.187976382179281&quot; &quot;0.375952764358561&quot; &quot;0.563929146537842&quot; ... ## .. ..$ : NULL ## $ meta :&#39;data.frame&#39;: 6 obs. of 3 variables: ## ..$ Parameter: chr [1:6] &quot;Start coordinate&quot; &quot;Stop coordinate&quot; &quot;Step size&quot; &quot;Optical Start&quot; ... ## ..$ Value : chr [1:6] &quot;31.5&quot; &quot;1314.1&quot; &quot;1000&quot; &quot;0.5&quot; ... ## ..$ Unit : chr [1:6] &quot;mm&quot; &quot;mm&quot; &quot;microns&quot; &quot;mm&quot; ... "],["radiographic-images-1.html", "2.4 Radiographic Images", " 2.4 Radiographic Images The function itraxR::itrax_radio() imports the processed radiographic images (*.tif) in a very similar way to that for the optical images, the main difference being the matrix only has two dimensions (length and width) as the image is greyscale. itrax_radiograph(file = &quot;CD166_19_S1/CD166_19_S1_RAD/radiograph0.tif&quot;, meta = &quot;CD166_19_S1/CD166_19_S1_RAD/document.txt&quot;) %&gt;% str() ## List of 2 ## $ image: num [1:6570, 1:67] 1 1 0.755 0.686 0.755 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : chr [1:6570] &quot;0&quot; &quot;0.200045669051606&quot; &quot;0.400091338103212&quot; &quot;0.600137007154818&quot; ... ## .. ..$ : chr [1:67] &quot;0&quot; &quot;0.200015220700152&quot; &quot;0.400030441400304&quot; &quot;0.600045662100457&quot; ... ## $ meta :&#39;data.frame&#39;: 10 obs. of 3 variables: ## ..$ Parameter: chr [1:10] &quot;Start coordinate&quot; &quot;Stop coordinate&quot; &quot;Step size&quot; &quot;Optical Start&quot; ... ## ..$ Value : chr [1:10] &quot;0.0&quot; &quot;1314.1&quot; &quot;200&quot; &quot;0.5&quot; ... ## ..$ Unit : chr [1:10] &quot;mm&quot; &quot;mm&quot; &quot;microns&quot; &quot;mm&quot; ... However, if there is a desire to manipulate the raw data from the radiographic image, some further work is required because the “pixel” is not square, but rectangular; that is to say the length of the pixel differs from its width. On the core scanner a single pixel has a width across the core of 20 μm, but has a variable coverage along the core (usually between 50 and 200 μm). The processed image downscales the pixel width to match the pixel length in order to force square pixels, losing some resolution along the way. In addition, it should be noted that unlike the optical images that always begin from position == 0, the radiographic images have defined start and end points just like an XRF scan, the parameters of which can be accessed from the $meta object, or using itraxR::itrax_meta(). "],["importing-everything.html", "2.5 Importing Everything", " 2.5 Importing Everything Given the structured nature of individual core section scans, it might be helpful to import everything into a single data object (list()). This is particularly helpful when dealing with large numbers of core sections. However, some care should be taken here, as it is easy to end up holding large quantities of data in memory, particularly where images are included. The structure of this can be adapted to your needs, but could look something like the following example. These are the data that will be used elsewhere in this guide. CD166_19_S1 &lt;- list(metadata = itrax_meta(&quot;CD166_19_S1/CD166_19_S1/document.txt&quot;), xrf = itrax_import(&quot;CD166_19_S1/CD166_19_S1/Results.txt&quot;, depth = 0, parameters = &quot;all&quot;), image = itrax_image(file = &quot;CD166_19_S1/CD166_19_S1/optical.tif&quot;, meta = &quot;CD166_19_S1/CD166_19_S1/document.txt&quot;), radiograph = itrax_radiograph(file = &quot;CD166_19_S1/CD166_19_S1_RAD/radiograph0.tif&quot;, meta = &quot;CD166_19_S1/CD166_19_S1_RAD/document.txt&quot;, trim = as.numeric(itrax_meta(&quot;CD166_19_S1/CD166_19_S1/document.txt&quot;)[6:7,2]))) CD166_19_S2 &lt;- list(metadata = itrax_meta(&quot;CD166_19_S2/CD166_19_S2/document.txt&quot;), xrf = itrax_import(&quot;CD166_19_S2/CD166_19_S2/Results.txt&quot;, depth = max(CD166_19_S1$xrf$depth), parameters = &quot;all&quot;), image = itrax_image(file = &quot;CD166_19_S2/CD166_19_S2/optical.tif&quot;, meta = &quot;CD166_19_S2/CD166_19_S2/document.txt&quot;), radiograph = itrax_radiograph(file = &quot;CD166_19_S2/CD166_19_S2_RAD/radiograph.tif&quot;, meta = &quot;CD166_19_S2/CD166_19_S2_RAD/document.txt&quot;, trim = as.numeric(itrax_meta(&quot;CD166_19_S2/CD166_19_S2/document.txt&quot;)[6:7,2]))) CD166_19_S3 &lt;- list(metadata = itrax_meta(&quot;CD166_19_S3/CD166_19_S3/document.txt&quot;), xrf = itrax_import(&quot;CD166_19_S3/CD166_19_S3/Results.txt&quot;, depth = max(CD166_19_S2$xrf$depth), parameters = &quot;all&quot;), image = itrax_image(file = &quot;CD166_19_S3/CD166_19_S3/optical.tif&quot;, meta = &quot;CD166_19_S3/CD166_19_S3/document.txt&quot;), radiograph = itrax_radiograph(file = &quot;CD166_19_S3/CD166_19_S3_RAD/radiograph.tif&quot;, meta = &quot;CD166_19_S3/CD166_19_S3_RAD/document.txt&quot;, trim = as.numeric(itrax_meta(&quot;CD166_19_S3/CD166_19_S3/document.txt&quot;)[6:7,2]))) CD166_19_xrf &lt;- itrax_join(list(S1 = CD166_19_S1$xrf, S2 = CD166_19_S2$xrf, S3 = CD166_19_S3$xrf)) "],["tidying-data.html", "Chapter 3 Tidying Data", " Chapter 3 Tidying Data In the functionality provided by itraxR, the need for data cleaning is much reduced. However, you may still encounter poor quality data that needs removing from subsequent analysis. This can be broadly defined as: Data at the start and end of the the core, where a volume of core material is “missing”. Measurements where the optical configuration is out of position (marked as validity == 0), often due to holes or stones in the core. Areas of the core with low total counts. Individual measurements that are statistical outliers. The easiest way to do this is using a tidyverse style sequence of pipes that set the observations of faulty data as NA. "],["low-count-rates.html", "3.1 Low Count Rates", " 3.1 Low Count Rates The count rate (“cps”, or counts-per-second) is the rate of energy event detection at the detector, and is a function of both the excitation beam condition (tube type, voltage and current) and the matrix. Because the tube type and voltage are often chosen based on other considerations, the operator usually only adjusts the tube current to optimise the count rate. The higher the total counts for each measurement, the better the measurement will be in terms of detection limits and uncertainties. Higher count rates allow for shorter dwell times, but this must be balanced against the need to minimise harmonics in the spectra. Harmonics can occur where the photon flux is so high that the detector cannot differentiate between two photons, and so registers the sum energy instead. For example, a particularly common phenomenon is the detection of two Fe Kα photons (energy 6.4 keV) as a single photon with the energy 12.8 keV. The graph below shows that for these cores there is the expected positive correlation between the count rate and the Fe Kα * 2 sum peak. To some extent the Q-Spec software will accommodate these harmonics, but operators commonly aim for a count rate of between 30-50 kcps. ggplot(data = CD166_19_xrf, mapping = aes(x = cps, y = `Fe a*2`)) + geom_point() Deletion criteria can be on the basis of count rates (excluding very low and high values), selected harmonics (e.g. Fe a*2), or both. An example is shown below. CD166_19_xrf %&gt;% mutate(in_tolerance = ifelse(cps &lt;=30000 | cps &gt;=60000 | is.na(cps) == TRUE, FALSE, TRUE)) %&gt;% ggplot(mapping = aes(x = depth, y = cps)) + geom_jitter(aes(col = in_tolerance)) + scale_x_reverse() + geom_hline(yintercept = c(30000, 60000)) "],["surface-slope.html", "3.2 Surface Slope", " 3.2 Surface Slope There is a relationship between the slope of the surface of the core material and the intensity for most elements. Hence areas with a large slope may produce an increase or decrease in a particular element intensity regardless of any actual change in the abundance of an element. This can be corrected for where the effect can be quantified experimentally, but Jarvis, Croudace, and Rothwell (2015) report results of experiments where the slope varies from -0.3 to +0.3 causing variation of around 120 to 80% of the true value. As such, we might initially seek to exclude areas of the core with a high slope. By default, itraxR::itrax_import() doesn’t import the sample surface variable, so the parameter parameters = \"all\" should be passed to access it. The computation is simple to perform using dplyr::lag(), and could be used as part of a conditional expression that would mark all measurements with a slope beyond a certain tolerance as having validity == FALSE. For example, the example below marks all values with a slope (in either direction) greater than 0.1 mm/200 μm (1:5) as being invalid. As shown for the core below, the core slope is well within the defined tolerances. CD166_19_xrf %&gt;% mutate(slope = `sample surface` - dplyr::lag(`sample surface`)) %&gt;% mutate(in_tolerance = ifelse(slope &lt;=-0.1 | slope &gt;=0.1 | is.na(slope) == TRUE, FALSE, TRUE)) %&gt;% ggplot(mapping = aes(x = depth, y = slope)) + scale_y_continuous(limits = c(-0.15, 0.15), oob = scales::squish) + geom_point(aes(col = in_tolerance)) + geom_hline(yintercept = c(-0.1, 0.1)) + scale_x_reverse() References "],["combining-validity-flags.html", "3.3 Combining “Validity” Flags", " 3.3 Combining “Validity” Flags It is often desirable to combine all deletion criteria into a single binary variable. This means combining multiple binary variables, returning FALSE if any of the values are FALSE, but only returning TRUE if all of the values are TRUE. CD166_19_xrf %&gt;% mutate(slope = `sample surface` - dplyr::lag(`sample surface`)) %&gt;% mutate(in_slope_tolerance = ifelse(slope &lt;=-0.1 | slope &gt;=0.1 | is.na(slope) == TRUE, FALSE, TRUE)) %&gt;% select(-slope) %&gt;% mutate(in_cps_tolerance = ifelse(cps &lt;=30000 | cps &gt;=60000 | is.na(cps) == TRUE, FALSE, TRUE)) %&gt;% rowwise() %&gt;% mutate(validity = !any(c(validity, in_slope_tolerance, in_cps_tolerance) == FALSE)) %&gt;% select(-c(in_slope_tolerance, in_cps_tolerance)) %&gt;% head() %&gt;% kable() depth MSE cps validity Al Si P S Cl Ar K Ca Sc Ti V Cr Mn Fe Ni Cu Zn Ga Ge Br Rb Sr Y Zr Pd Cd I Cs Ba Nd Sm Yb Ta W Pb Bi Mo inc Mo coh filename position sample surface E-gain E-offset F-slope F-offset Fe a*2 Fe a+b S1 S2 S3 Dt label 1 1.41 34525 FALSE 76 275 0 10 1318 604 2565 112734 0 1661 51 258 508 35168 123 277 205 4 0 491 329 8306 15 255 31 13 38 0 63 17 43 144 789 1992 77 72 26323 8799 C:166_19_(2020)_processed166_19_S1166_19_S1data000001.spe 32.54 6.39 0.010267 -0.009931 0.0099 0.077115 80 15 366 179 235 0.106 S1 2 1.57 38370 TRUE 57 306 0 0 1513 595 2628 144287 14 1806 88 326 559 36494 104 230 268 48 40 605 76 9181 140 322 78 34 48 0 48 67 46 282 776 2019 0 136 26778 9117 C:166_19_(2020)_processed166_19_S1166_19_S1data000002.spe 33.54 6.42 0.010267 -0.009931 0.0099 0.077115 209 531 256 242 302 0.104 S1 3 1.55 39796 TRUE 74 330 0 32 1470 506 2378 162938 0 2121 22 301 483 35952 134 150 123 0 43 550 295 9644 119 280 75 55 80 0 25 44 39 158 703 2016 13 199 26550 9303 C:166_19_(2020)_processed166_19_S1166_19_S1data000003.spe 34.54 6.42 0.010267 -0.009931 0.0099 0.077115 127 59 302 190 270 0.104 S1 4 1.41 40022 TRUE 26 206 0 21 1312 555 2265 153194 0 2031 75 306 485 35512 144 206 239 0 0 609 313 9940 107 475 66 24 67 0 60 75 64 218 794 2160 152 134 28310 9886 C:166_19_(2020)_processed166_19_S1166_19_S1data000004.spe 35.54 6.43 0.010267 -0.009931 0.0099 0.077115 106 149 257 291 305 0.108 S1 5 1.41 41973 TRUE 53 233 0 37 1740 591 2947 135879 106 1826 89 440 738 44303 166 276 240 0 0 659 304 10287 180 160 31 34 23 0 132 42 36 163 919 2344 54 157 31356 10140 C:166_19_(2020)_processed166_19_S1166_19_S1data000005.spe 36.54 6.44 0.010267 -0.009931 0.0099 0.077115 116 18 325 311 380 0.111 S1 6 1.36 41268 TRUE 27 347 0 28 1576 504 3179 132183 14 1923 107 401 792 45283 151 250 294 40 48 709 318 9917 106 312 72 28 58 0 93 97 12 184 852 2336 54 182 30631 9968 C:166_19_(2020)_processed166_19_S1166_19_S1data000006.spe 37.54 6.46 0.010267 -0.009931 0.0099 0.077115 77 114 406 296 345 0.111 S1 Bear in mind that this doesn’t remove observations considered defective, only marks them has validity == FALSE. If they are to be excluded from subsequent analysis, they should be removed using filter(validity == TRUE). CD166_19_xrf %&gt;% mutate(slope = `sample surface` - dplyr::lag(`sample surface`)) %&gt;% mutate(in_slope_tolerance = ifelse(slope &lt;=-0.1 | slope &gt;=0.1 | is.na(slope) == TRUE, FALSE, TRUE)) %&gt;% select(-slope) %&gt;% mutate(in_cps_tolerance = ifelse(cps &lt;=30000 | cps &gt;=60000 | is.na(cps) == TRUE, FALSE, TRUE)) %&gt;% rowwise() %&gt;% mutate(validity = !any(c(validity, in_slope_tolerance, in_cps_tolerance) == FALSE)) %&gt;% select(-c(in_slope_tolerance, in_cps_tolerance)) %&gt;% filter(validity == TRUE) %&gt;% head() ## [90m# A tibble: 6 x 56[39m ## [90m# Rowwise: [39m ## depth MSE cps validity Al Si P S Cl Ar K Ca ## [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;lgl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m ## [90m1[39m 2 1.57 [4m3[24m[4m8[24m370 TRUE 57 306 0 0 [4m1[24m513 595 [4m2[24m628 [4m1[24m[4m4[24m[4m4[24m287 ## [90m2[39m 3 1.55 [4m3[24m[4m9[24m796 TRUE 74 330 0 32 [4m1[24m470 506 [4m2[24m378 [4m1[24m[4m6[24m[4m2[24m938 ## [90m3[39m 4 1.41 [4m4[24m[4m0[24m022 TRUE 26 206 0 21 [4m1[24m312 555 [4m2[24m265 [4m1[24m[4m5[24m[4m3[24m194 ## [90m4[39m 5 1.41 [4m4[24m[4m1[24m973 TRUE 53 233 0 37 [4m1[24m740 591 [4m2[24m947 [4m1[24m[4m3[24m[4m5[24m879 ## [90m5[39m 6 1.36 [4m4[24m[4m1[24m268 TRUE 27 347 0 28 [4m1[24m576 504 [4m3[24m179 [4m1[24m[4m3[24m[4m2[24m183 ## [90m6[39m 7 1.52 [4m4[24m[4m0[24m977 TRUE 72 337 0 59 [4m1[24m605 584 [4m3[24m376 [4m1[24m[4m3[24m[4m4[24m094 ## [90m# … with 44 more variables: Sc [3m[90m&lt;dbl&gt;[90m[23m, Ti [3m[90m&lt;dbl&gt;[90m[23m, V [3m[90m&lt;dbl&gt;[90m[23m, Cr [3m[90m&lt;dbl&gt;[90m[23m, Mn [3m[90m&lt;dbl&gt;[90m[23m,[39m ## [90m# Fe [3m[90m&lt;dbl&gt;[90m[23m, Ni [3m[90m&lt;dbl&gt;[90m[23m, Cu [3m[90m&lt;dbl&gt;[90m[23m, Zn [3m[90m&lt;dbl&gt;[90m[23m, Ga [3m[90m&lt;dbl&gt;[90m[23m, Ge [3m[90m&lt;dbl&gt;[90m[23m, Br [3m[90m&lt;dbl&gt;[90m[23m,[39m ## [90m# Rb [3m[90m&lt;dbl&gt;[90m[23m, Sr [3m[90m&lt;dbl&gt;[90m[23m, Y [3m[90m&lt;dbl&gt;[90m[23m, Zr [3m[90m&lt;dbl&gt;[90m[23m, Pd [3m[90m&lt;dbl&gt;[90m[23m, Cd [3m[90m&lt;dbl&gt;[90m[23m, I [3m[90m&lt;dbl&gt;[90m[23m,[39m ## [90m# Cs [3m[90m&lt;dbl&gt;[90m[23m, Ba [3m[90m&lt;dbl&gt;[90m[23m, Nd [3m[90m&lt;dbl&gt;[90m[23m, Sm [3m[90m&lt;dbl&gt;[90m[23m, Yb [3m[90m&lt;dbl&gt;[90m[23m, Ta [3m[90m&lt;dbl&gt;[90m[23m, W [3m[90m&lt;dbl&gt;[90m[23m,[39m ## [90m# Pb [3m[90m&lt;dbl&gt;[90m[23m, Bi [3m[90m&lt;dbl&gt;[90m[23m, `Mo inc` [3m[90m&lt;dbl&gt;[90m[23m, `Mo coh` [3m[90m&lt;dbl&gt;[90m[23m, filename [3m[90m&lt;chr&gt;[90m[23m,[39m ## [90m# position [3m[90m&lt;dbl&gt;[90m[23m, `sample surface` [3m[90m&lt;dbl&gt;[90m[23m, `E-gain` [3m[90m&lt;dbl&gt;[90m[23m, `E-offset` [3m[90m&lt;dbl&gt;[90m[23m,[39m ## [90m# `F-slope` [3m[90m&lt;dbl&gt;[90m[23m, `F-offset` [3m[90m&lt;dbl&gt;[90m[23m, `Fe a*2` [3m[90m&lt;dbl&gt;[90m[23m, `Fe a+b` [3m[90m&lt;dbl&gt;[90m[23m,[39m ## [90m# S1 [3m[90m&lt;dbl&gt;[90m[23m, S2 [3m[90m&lt;dbl&gt;[90m[23m, S3 [3m[90m&lt;dbl&gt;[90m[23m, Dt [3m[90m&lt;dbl&gt;[90m[23m, label [3m[90m&lt;chr&gt;[90m[23m[39m "],["tube-current.html", "3.4 Tube current", " 3.4 Tube current Although element peak areas are not exactly linearly related to tube current, they can be approximated to a linear relationship (see Jarvis, Croudace, and Rothwell (2015)). The Q-Spec software can report either peak areas (n) or intensities (n/mA), and it is easy to tell which you are using: peak areas are always integers, but intensities are always fractions. It is easy to adjust from one to the other: current &lt;- as.numeric(CD166_19_S1$metadata[18, 2]) CD166_19_S1$xrf %&gt;% mutate(intensity_Fe = round(Fe/current, 3)) %&gt;% # convert to intensity mutate(peakarea_Fe = round(intensity_Fe*current)) %&gt;% # convert to peak area select(Fe, intensity_Fe, peakarea_Fe) %&gt;% head() ## [90m# A tibble: 6 x 3[39m ## Fe intensity_Fe peakarea_Fe ## [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m ## [90m1[39m [4m3[24m[4m5[24m168 [4m1[24m172. [4m3[24m[4m5[24m168 ## [90m2[39m [4m3[24m[4m6[24m494 [4m1[24m216. [4m3[24m[4m6[24m494 ## [90m3[39m [4m3[24m[4m5[24m952 [4m1[24m198. [4m3[24m[4m5[24m952 ## [90m4[39m [4m3[24m[4m5[24m512 [4m1[24m184. [4m3[24m[4m5[24m512 ## [90m5[39m [4m4[24m[4m4[24m303 [4m1[24m477. [4m4[24m[4m4[24m303 ## [90m6[39m [4m4[24m[4m5[24m283 [4m1[24m509. [4m4[24m[4m5[24m283 rm(current) References "],["dead-time.html", "3.5 Dead Time", " 3.5 Dead Time In silicone drift ED-XRF detectors the electronics are only so fast. This limits the flux of photons into the detector that can be measured. When the count rate is high, the detector will not be making observations whilst the electronics “catch-up”; this is the dead-time, and here it is expressed as a fraction of the overall dwell time. When the system is optimised variations in dead-time are usually small enough to be ignored, but where the matrix or configuration leads to large variations in dead-time they should be corrected for. ggplot(data = CD166_19_xrf, aes(x = depth, y = Dt)) + scale_x_reverse() + scale_y_continuous(sec.axis = sec_axis( trans=~(.+(1-mean(CD166_19_xrf$Dt, na.rm = TRUE))), name=&quot;Correction Factor&quot;)) + geom_line() + geom_hline(yintercept = mean(CD166_19_xrf$Dt, na.rm = TRUE), linetype = &quot;dotted&quot;) CD166_19_xrf %&gt;% mutate(newDt = Dt+(1-mean(CD166_19_xrf$Dt, na.rm = TRUE))) %&gt;% mutate(across(any_of(elementsList)) * newDt) %&gt;% select(-newDt) %&gt;% head() ## [90m# A tibble: 6 x 56[39m ## depth MSE cps validity Al Si P S Cl Ar K Ca ## [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;lgl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m ## [90m1[39m 1 1.41 [4m3[24m[4m4[24m525 TRUE 76.2 276. 0 10.0 [4m1[24m322. 606. [4m2[24m573. 1.13[90me[39m5 ## [90m2[39m 2 1.57 [4m3[24m[4m8[24m370 TRUE 57.1 306. 0 0 [4m1[24m514. 596. [4m2[24m631. 1.44[90me[39m5 ## [90m3[39m 3 1.55 [4m3[24m[4m9[24m796 TRUE 74.1 330. 0 32.0 [4m1[24m471. 506. [4m2[24m380. 1.63[90me[39m5 ## [90m4[39m 4 1.41 [4m4[24m[4m0[24m022 TRUE 26.1 207. 0 21.1 [4m1[24m319. 558. [4m2[24m276. 1.54[90me[39m5 ## [90m5[39m 5 1.41 [4m4[24m[4m1[24m973 TRUE 53.4 235. 0 37.3 [4m1[24m754. 596. [4m2[24m970. 1.37[90me[39m5 ## [90m6[39m 6 1.36 [4m4[24m[4m1[24m268 TRUE 27.2 350. 0 28.2 [4m1[24m589. 508. [4m3[24m204. 1.33[90me[39m5 ## [90m# … with 44 more variables: Sc [3m[90m&lt;dbl&gt;[90m[23m, Ti [3m[90m&lt;dbl&gt;[90m[23m, V [3m[90m&lt;dbl&gt;[90m[23m, Cr [3m[90m&lt;dbl&gt;[90m[23m, Mn [3m[90m&lt;dbl&gt;[90m[23m,[39m ## [90m# Fe [3m[90m&lt;dbl&gt;[90m[23m, Ni [3m[90m&lt;dbl&gt;[90m[23m, Cu [3m[90m&lt;dbl&gt;[90m[23m, Zn [3m[90m&lt;dbl&gt;[90m[23m, Ga [3m[90m&lt;dbl&gt;[90m[23m, Ge [3m[90m&lt;dbl&gt;[90m[23m, Br [3m[90m&lt;dbl&gt;[90m[23m,[39m ## [90m# Rb [3m[90m&lt;dbl&gt;[90m[23m, Sr [3m[90m&lt;dbl&gt;[90m[23m, Y [3m[90m&lt;dbl&gt;[90m[23m, Zr [3m[90m&lt;dbl&gt;[90m[23m, Pd [3m[90m&lt;dbl&gt;[90m[23m, Cd [3m[90m&lt;dbl&gt;[90m[23m, I [3m[90m&lt;dbl&gt;[90m[23m,[39m ## [90m# Cs [3m[90m&lt;dbl&gt;[90m[23m, Ba [3m[90m&lt;dbl&gt;[90m[23m, Nd [3m[90m&lt;dbl&gt;[90m[23m, Sm [3m[90m&lt;dbl&gt;[90m[23m, Yb [3m[90m&lt;dbl&gt;[90m[23m, Ta [3m[90m&lt;dbl&gt;[90m[23m, W [3m[90m&lt;dbl&gt;[90m[23m,[39m ## [90m# Pb [3m[90m&lt;dbl&gt;[90m[23m, Bi [3m[90m&lt;dbl&gt;[90m[23m, `Mo inc` [3m[90m&lt;dbl&gt;[90m[23m, `Mo coh` [3m[90m&lt;dbl&gt;[90m[23m, filename [3m[90m&lt;chr&gt;[90m[23m,[39m ## [90m# position [3m[90m&lt;dbl&gt;[90m[23m, `sample surface` [3m[90m&lt;dbl&gt;[90m[23m, `E-gain` [3m[90m&lt;dbl&gt;[90m[23m, `E-offset` [3m[90m&lt;dbl&gt;[90m[23m,[39m ## [90m# `F-slope` [3m[90m&lt;dbl&gt;[90m[23m, `F-offset` [3m[90m&lt;dbl&gt;[90m[23m, `Fe a*2` [3m[90m&lt;dbl&gt;[90m[23m, `Fe a+b` [3m[90m&lt;dbl&gt;[90m[23m,[39m ## [90m# S1 [3m[90m&lt;dbl&gt;[90m[23m, S2 [3m[90m&lt;dbl&gt;[90m[23m, S3 [3m[90m&lt;dbl&gt;[90m[23m, Dt [3m[90m&lt;dbl&gt;[90m[23m, label [3m[90m&lt;chr&gt;[90m[23m[39m "],["correcting-for-water-content.html", "3.6 Correcting for Water Content", " 3.6 Correcting for Water Content Water content can be corrected for as a simple dilution effect, for example, if a sample contains 50% water by weight, the peak intensity can be doubled. The water content must be determined using some other lab method (e.g. loss-on-ignition), and it is likely that this can only be performed on samples larger than the original scan interval (e.g. 10 mm subsamples). A conservative approach is to use the itrax_averaging() function to re-sample the XRF data to the resolution of the water content data, or the reverse (upsampling the water content data) might be applied with caution. For some scans the Mo inc./Mo coh. varies with water content and can be used as a proxy to correct for water content. "],["correcting-grain-size.html", "3.7 Correcting Grain Size", " 3.7 Correcting Grain Size Grain size variations are known the affect the detection of some elements. Grain size determinations made using analytical equipment (e.g. a laser granulometer) can be used to correct for grain size. "],["high-signal-to-noise-ratios.html", "3.8 High Signal-to-noise Ratios", " 3.8 High Signal-to-noise Ratios The inclusion of an element in an XRF dataset does not necessarily mean that the element is well-detected, and some elements will be so poorly detected that those data can be removed. "],["plotting.html", "Chapter 4 Plotting", " Chapter 4 Plotting There are a number of plotting options included in base R and some palaeoenvironmental packages like analouge, but here we will use ggplot2 and compatible packages. We will also be using tidypaleo, a package made available by Dewey Dunnington on Github. "],["plotting-xrf-data.html", "4.1 Plotting XRF Data", " 4.1 Plotting XRF Data For simple biplots, ggplot2 provides the following solution. This includes different colour coding to differentiate the core sections. ggplot(data = na.omit(CD166_19_xrf), mapping = aes(x = depth, y = `Mo coh`/`Mo inc`)) + geom_line(aes(color = label)) + coord_flip() + scale_x_reverse() + labs(x = &quot;Depth [mm]&quot;, color = &quot;Core&quot;) + theme_classic() + theme(legend.position = &quot;none&quot;) Where a traditional stratigraphic plot is desired, the tidypaleo package provides useful functionality for producing these. However, the data does need to converted to long-form from the existing table. In this way tidypaleo::facet_geochem_gridh works in a way similar to ggplot::facet_wrap but has been creates a stratigraphic plot. The elementsList is used with select(any_of()) to include only columns that are chemical elements. Depth and label are also added because they are used in the plot. Although this is useful for producing large-format summary diagrams of the data, these do not render well in smaller plot areas, so a small subset of variables has been selected manually; see the code comments below. Note that in the line mutate(), the vector passed to levels = controls the order in which the plots appear. In this example, they will appear in order of atomic weight, and the coh/inc ratio will always be last. xrfStrat &lt;- CD166_19_xrf %&gt;% mutate(`coh/inc` = `Mo coh`/`Mo inc`) %&gt;% select(any_of(elementsList), `coh/inc`, depth, label) %&gt;% # this is useful but produces a very large plot that doesn&#39;t render well select(Fe, Ti, `coh/inc`, Mn, depth, label) %&gt;% # a smaller set of elements is defined here manually. tidyr::pivot_longer(!c(&quot;depth&quot;, &quot;label&quot;), names_to = &quot;elements&quot;, values_to = &quot;peakarea&quot;) %&gt;% tidyr::drop_na() %&gt;% mutate(elements = factor(elements, levels = c(elementsList, &quot;coh/inc&quot;))) %&gt;% # note that the levels controls the order ggplot(aes(x = peakarea, y = depth)) + tidypaleo::geom_lineh(aes(color = label)) + scale_y_reverse() + scale_x_continuous(n.breaks = 2) + facet_geochem_gridh(vars(elements)) + labs(x = &quot;peak area&quot;, y = &quot;Depth [mm]&quot;) + tidypaleo::theme_paleo() + theme(legend.position = &quot;none&quot;) print(xrfStrat) Notice that in the previous example the data must be converted to “long-form” from “short-form” for tidypaleo, using tidyr::pivot_longer. “Short-form” data has observations as rows, and variables as columns, whereas “long-form” data has a column for names, which in this case are the elements, and a column for values, in this case the peak intensities. This results in many rows, but few columns. glimpse( CD166_19_xrf %&gt;% select(any_of(elementsList), depth, label) %&gt;% tidyr::pivot_longer(!c(&quot;depth&quot;, &quot;label&quot;), names_to = &quot;elements&quot;, values_to = &quot;peakarea&quot;) ) ## Rows: 151,416 ## Columns: 4 ## $ depth [3m[90m&lt;dbl&gt;[39m[23m 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, … ## $ label [3m[90m&lt;chr&gt;[39m[23m &quot;S1&quot;, &quot;S1&quot;, &quot;S1&quot;, &quot;S1&quot;, &quot;S1&quot;, &quot;S1&quot;, &quot;S1&quot;, &quot;S1&quot;, &quot;S1&quot;, &quot;S1&quot;, … ## $ elements [3m[90m&lt;chr&gt;[39m[23m &quot;Al&quot;, &quot;Si&quot;, &quot;P&quot;, &quot;S&quot;, &quot;Cl&quot;, &quot;Ar&quot;, &quot;K&quot;, &quot;Ca&quot;, &quot;Sc&quot;, &quot;Ti&quot;, &quot;V&quot;… ## $ peakarea [3m[90m&lt;dbl&gt;[39m[23m 76, 275, 0, 10, 1318, 604, 2565, 112734, 0, 1661, 51, 258, 5… "],["plotting-images.html", "4.2 Plotting Images", " 4.2 Plotting Images The package itraxR provides functions for importing and creating basic plots of both the photographic and radiographic images. For the optical images, it is almost always necessary to trim the image to the extent of the actual scan, or extraneous image is included (e.g. the calibration card in the example shown below). The function itraxR::itrax_image() allows the extent of the scan to be defined, or extracted from the metadata. In the example below, trim = FALSE forces the whole image to be shown. When dealing with high aspect ratio images like these, it is often useful to use svgPanZoom::svgPanZoom() instead of print() to view the output. myImage &lt;- itrax_image(file = &quot;CD166_19_S1/CD166_19_S1/optical.tif&quot;, meta = &quot;CD166_19_S1/CD166_19_S1/document.txt&quot;, trim = FALSE, plot = TRUE ) For radiographic images the function itraxR::itrax_radiograph() can be used using an identical syntax as itraxR::itrax_image(). Often the contrast needs to be adjusted, so a contrast-adjusted radiograph is supplied in the example data (radiograph0.tif). myRadio &lt;- itrax_radiograph(file = &quot;CD166_19_S1/CD166_19_S1_RAD/radiograph0.tif&quot;, meta = &quot;CD166_19_S1/CD166_19_S1_RAD/document.txt&quot;, plot = TRUE ) The simple plots generated as a side effect of these functions are sometimes sufficient for simple plots, but for more complex diagrams you will need to generate them from scratch. For example, it is often desirable to overplot the radiograph on the optical image. The code below does this. Note the calculations made for the xmin = and ymin = parameters for annotation_custom() when adding the radiograph rasterGrob(); these correctly position the radiograph along the centre of the image. ggplot() + ylim(rev(range(as.numeric(row.names(myImage$image))))) + scale_x_continuous(breaks = round(range(as.numeric(colnames(myImage$image))), 0), limits = range(as.numeric(colnames(myImage$image)))) + labs(y = &quot;Position [mm]&quot;, x = &quot;[mm]&quot;) + annotation_custom(rasterGrob(myImage$image, width = unit(1, &quot;npc&quot;), height = unit(1, &quot;npc&quot;)), ymax = max(as.numeric(row.names(myImage$image)))/-1, ymin = min(as.numeric(row.names(myImage$image)))/-1, xmin = min(as.numeric(colnames(myImage$image))), xmax = max(as.numeric(colnames(myImage$image))) ) + annotation_custom(rasterGrob(myRadio$image, width = unit(1, &quot;npc&quot;), height = unit(1, &quot;npc&quot;)), ymax = max(as.numeric(row.names(myRadio$image)))/-1, ymin = min(as.numeric(row.names(myRadio$image)))/-1, xmin = mean(as.numeric(colnames(myImage$image))) - mean(as.numeric(colnames(myRadio$image))), xmax = mean(as.numeric(colnames(myImage$image))) + mean(as.numeric(colnames(myRadio$image))) ) + coord_fixed(ratio = 1) It is often desirable to combine a sequence of cores. This is trivial for cores like CD166_19 where there are no overlapping sections. However, note that the coring depth information is different from the position that these images are referenced to. The coring depth is not contained in any of the Itrax metadata, and should be recorded elsewhere, whereas position refers to the coordinates on the Itrax core holder. In the code below the depth information is extracted from the combined XRF data created in a previous chapter (for example using max(CD166_19[which(CD166_19$label == \"S2\"),]$depth) to get the maximum depth of the middle section. The radiographs can be added in the same fashion as the previous example. ggplot() + ylim(rev(range(CD166_19_xrf$depth))) + scale_x_continuous(breaks = round(range(as.numeric(colnames(CD166_19_S1$image$image))), 0), limits = range(as.numeric(colnames(CD166_19_S1$image$image)))) + coord_fixed(ratio = 1) + labs(y = &quot;Depth [mm]&quot;, x = &quot;[mm]&quot;) + annotation_custom(rasterGrob(CD166_19_S1$image$image, width = unit(1, &quot;npc&quot;), height = unit(1, &quot;npc&quot;)), ymax = max(CD166_19_S1$xrf$depth)/-1, ymin = min(CD166_19_S1$xrf$depth)/-1, xmin = min(as.numeric(colnames(CD166_19_S1$image$image))), xmax = max(as.numeric(colnames(CD166_19_S1$image$image))) ) + annotation_custom(rasterGrob(CD166_19_S2$image$image, width = unit(1, &quot;npc&quot;), height = unit(1, &quot;npc&quot;)), ymax = max(CD166_19_S2$xrf$depth)/-1, ymin = min(CD166_19_S2$xrf$depth)/-1, xmin = min(as.numeric(colnames(CD166_19_S2$image$image))), xmax = max(as.numeric(colnames(CD166_19_S2$image$image))) ) + annotation_custom(rasterGrob(CD166_19_S3$image$image, width = unit(1, &quot;npc&quot;), height = unit(1, &quot;npc&quot;)), ymax = max(CD166_19_S3$xrf$depth)/-1, ymin = min(CD166_19_S3$xrf$depth)/-1, xmin = min(as.numeric(colnames(CD166_19_S3$image$image))), xmax = max(as.numeric(colnames(CD166_19_S3$image$image))) ) Where there are overlaps it is often desirable to plot the cores adjacent to one another. It is simply a case of adjusting the xmin = and xmax = parameters in the annotation_custom() function for every other section. In this context the x-axis labels become largely meaningless and can be omitted. ggplot() + ylim(rev(range(CD166_19_xrf$depth))) + scale_x_continuous(breaks = round(c(0, max(as.numeric(colnames(CD166_19_S2$image$image)))*2)), limits = c(0, max(as.numeric(colnames(CD166_19_S2$image$image)))*2)) + coord_fixed(ratio = 1) + labs(y = &quot;Depth [mm]&quot;, x = &quot;[mm]&quot;) + annotation_custom(rasterGrob(CD166_19_S1$image$image, width = unit(1, &quot;npc&quot;), height = unit(1, &quot;npc&quot;)), ymax = max(CD166_19_S1$xrf$depth)/-1, ymin = min(CD166_19_S1$xrf$depth)/-1, xmin = min(as.numeric(colnames(CD166_19_S1$image$image))), xmax = max(as.numeric(colnames(CD166_19_S1$image$image))) ) + annotation_custom(rasterGrob(CD166_19_S2$image$image, width = unit(1, &quot;npc&quot;), height = unit(1, &quot;npc&quot;)), ymax = max(CD166_19_S2$xrf$depth)/-1, ymin = min(CD166_19_S2$xrf$depth)/-1, xmin = max(as.numeric(colnames(CD166_19_S2$image$image))), xmax = max(as.numeric(colnames(CD166_19_S2$image$image)))*2 ) + annotation_custom(rasterGrob(CD166_19_S3$image$image, width = unit(1, &quot;npc&quot;), height = unit(1, &quot;npc&quot;)), ymax = max(CD166_19_S3$xrf$depth)/-1, ymin = min(CD166_19_S3$xrf$depth)/-1, xmin = min(as.numeric(colnames(CD166_19_S3$image$image))), xmax = max(as.numeric(colnames(CD166_19_S3$image$image))) ) Note that omitting the line coord_fixed(ratio = 1) allows the aspect ratio of the plot to be reshaped. Although usually it is desirable to keep the plot in the correct shape, sometimes for very long sequences the images end up so narrow as to be quite useless, so the x-axis can be stretched to accentuate the features in it. The example below simply omits the coord_fixed() line from the previous example. Recall that ggplot objects can be saved and recalled rather than immediately printed. Let us take the plot generated in a previous example, but assign it using imagePlot &lt;- ggplot() + .... The radiographs can be added afterwards without starting from scratch. We can also modify plot parameters, for example, the x-axis labels can be removed. imagePlot &lt;- imagePlot + annotation_custom(rasterGrob(CD166_19_S1$radiograph$image, width = unit(1, &quot;npc&quot;), height = unit(1, &quot;npc&quot;)), ymin = min(CD166_19_S1$xrf$depth)/-1, ymax = max(CD166_19_S1$xrf$depth)/-1, xmin = mean(as.numeric(colnames(CD166_19_S1$image$image))) - mean(as.numeric(colnames(CD166_19_S1$radiograph$image))), xmax = mean(as.numeric(colnames(CD166_19_S1$image$image))) + mean(as.numeric(colnames(CD166_19_S1$radiograph$image))) ) + annotation_custom(rasterGrob(CD166_19_S2$radiograph$image, width = unit(1, &quot;npc&quot;), height = unit(1, &quot;npc&quot;)), ymin = min(CD166_19_S2$xrf$depth)/-1, ymax = max(CD166_19_S2$xrf$depth)/-1, xmin = mean(as.numeric(colnames(CD166_19_S2$image$image))) - mean(as.numeric(colnames(CD166_19_S2$radiograph$image))), xmax = mean(as.numeric(colnames(CD166_19_S2$image$image))) + mean(as.numeric(colnames(CD166_19_S2$radiograph$image))) ) + annotation_custom(rasterGrob(CD166_19_S3$radiograph$image, width = unit(1, &quot;npc&quot;), height = unit(1, &quot;npc&quot;)), ymin = min(CD166_19_S3$xrf$depth)/-1, ymax = max(CD166_19_S3$xrf$depth)/-1, xmin = mean(as.numeric(colnames(CD166_19_S3$image$image))) - mean(as.numeric(colnames(CD166_19_S3$radiograph$image))), xmax = mean(as.numeric(colnames(CD166_19_S3$image$image))) + mean(as.numeric(colnames(CD166_19_S3$radiograph$image))) ) + theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank()) print(imagePlot + coord_fixed(ratio = 1)) Finally, it may be necessary to plot the images horizontally rather than the more traditional vertical plots often used in down-core data presentation. aperm() and t() may be used for the optical and radiographic images respectively to transpose the x- and y-coordinates, but the images will need to be mirrored (using []) so that the tops of the sections are on the right-hand side and the graphs run from oldest to youngest when read left-to-right, in the generally accepted order of these types of graph. For the example below, this is achieved in the first and second lines for the optical and radiographic images respectively. mySidewaysImage &lt;- aperm(CD166_19_S1$image$image, c(2,1,3))[, dim(aperm(CD166_19_S1$image$image, c(2,1,3)))[2]:1, ] mySidewaysRadio &lt;- t(CD166_19_S1$radiograph$image)[, dim(t(CD166_19_S1$radiograph$image))[2]:1] ggplot() + xlim(rev(range(as.numeric(colnames(mySidewaysImage))))) + scale_y_continuous(breaks = round(range(as.numeric(row.names(mySidewaysImage))), 0), limits = range(as.numeric(row.names(mySidewaysImage)))) + labs(y = &quot;[mm]&quot;, x = &quot;Position [mm]&quot;) + annotation_custom(rasterGrob(mySidewaysImage, width = unit(1, &quot;npc&quot;), height = unit(1, &quot;npc&quot;)), xmax = max(as.numeric(colnames(mySidewaysImage)))/-1, xmin = min(as.numeric(colnames(mySidewaysImage)))/-1, ymin = min(as.numeric(row.names(mySidewaysImage))), ymax = max(as.numeric(row.names(mySidewaysImage))) ) + annotation_custom(rasterGrob(mySidewaysRadio, width = unit(1, &quot;npc&quot;), height = unit(1, &quot;npc&quot;)), xmax = max(as.numeric(colnames(mySidewaysRadio)))/-1, xmin = min(as.numeric(colnames(mySidewaysRadio)))/-1, ymin = mean(as.numeric(row.names(mySidewaysImage))) - mean(as.numeric(row.names(mySidewaysRadio))), ymax = mean(as.numeric(row.names(mySidewaysImage))) + mean(as.numeric(row.names(mySidewaysRadio))) ) + coord_fixed(ratio = 1) "],["combining-images-with-xrf-data.html", "4.3 Combining Images with XRF Data", " 4.3 Combining Images with XRF Data It is possible to combine different plots. For example, it is often desirable to plot the XRF data alongside the core imagery. By not passing coord_fixed(ratio = 1) to the image plot, its relative width can be controlled via widths =, which makes for a visually pleasing plot. Note also that the y-axis labels have been removed from all but one of the plots to avoid duplication. egg::ggarrange(imagePlot + theme_paleo(), xrfStrat + theme(axis.title.y = element_blank(), axis.text.y = element_blank(), axis.ticks.y = element_blank()), ncol = 2, widths = c(1, 4) # these are relative. For c(1, 5), the first plot will be 1/5th the width of the second. ) "],["transforming-data.html", "Chapter 5 Transforming Data", " Chapter 5 Transforming Data The XRF data typically reported from the Itrax core scanner come from the spectral processing software Q-Spec. The output is usually in the form of an intensity, which is a dimensionless metric derived from the size of the spectral peak for a particular element, above the background Bremsstrahlung radiation, sometimes normalised for the tube current and/or counting time. "],["ratios-and-normalisation.html", "5.1 Ratios and Normalisation", " 5.1 Ratios and Normalisation These data are compositional, and represent the changes in the relative proportions of all components of the matrix, measured and un-measured. As such it is likely the data will need transforming for certain types of multivariate analysis. As previously mentioned, these data are dimensionless, and as such do not represent a quantity, but are directly related to the absolute amount of a particular element in the matrix. It is often the case that ratios of elements are used to represent changes in composition — this is sometimes referred to as normalisation, or normalising one element against another. It is trivial to calculate element ratios, to the extent that these can often simply be calculated where they are required rather than saving them to memory. For example, if a plot of the Compton divided by the Rayleigh scatter was desired, there is no need to save the computed value to a new variable (e.g. coh_inc &lt;- df$Mo.coh/df$Mo.inc) — simply define the calculation during plotting. To calculate ratios for all elements at once, use mutate(across(any_ofelementsList)), where elementsList is a list of chemical elements extracted from data(PeriodicTable). CD166_19_xrf %&gt;% mutate(across(any_of(elementsList)) /`Mo inc`) %&gt;% head() ## [90m# A tibble: 6 x 56[39m ## depth MSE cps validity Al Si P S Cl Ar K ## [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;lgl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m ## [90m1[39m 1 1.41 [4m3[24m[4m4[24m525 TRUE 2.89[90me[39m[31m-3[39m 0.010[4m4[24m 0 3.80[90me[39m[31m-4[39m 0.050[4m1[24m 0.022[4m9[24m 0.097[4m4[24m ## [90m2[39m 2 1.57 [4m3[24m[4m8[24m370 TRUE 2.13[90me[39m[31m-3[39m 0.011[4m4[24m 0 0. [90m [39m 0.056[4m5[24m 0.022[4m2[24m 0.098[4m1[24m ## [90m3[39m 3 1.55 [4m3[24m[4m9[24m796 TRUE 2.79[90me[39m[31m-3[39m 0.012[4m4[24m 0 1.21[90me[39m[31m-3[39m 0.055[4m4[24m 0.019[4m1[24m 0.089[4m6[24m ## [90m4[39m 4 1.41 [4m4[24m[4m0[24m022 TRUE 9.18[90me[39m[31m-4[39m 0.007[4m2[24m[4m8[24m 0 7.42[90me[39m[31m-4[39m 0.046[4m3[24m 0.019[4m6[24m 0.080[4m0[24m ## [90m5[39m 5 1.41 [4m4[24m[4m1[24m973 TRUE 1.69[90me[39m[31m-3[39m 0.007[4m4[24m[4m3[24m 0 1.18[90me[39m[31m-3[39m 0.055[4m5[24m 0.018[4m8[24m 0.094[4m0[24m ## [90m6[39m 6 1.36 [4m4[24m[4m1[24m268 TRUE 8.81[90me[39m[31m-4[39m 0.011[4m3[24m 0 9.14[90me[39m[31m-4[39m 0.051[4m5[24m 0.016[4m5[24m 0.104 ## [90m# … with 45 more variables: Ca [3m[90m&lt;dbl&gt;[90m[23m, Sc [3m[90m&lt;dbl&gt;[90m[23m, Ti [3m[90m&lt;dbl&gt;[90m[23m, V [3m[90m&lt;dbl&gt;[90m[23m, Cr [3m[90m&lt;dbl&gt;[90m[23m,[39m ## [90m# Mn [3m[90m&lt;dbl&gt;[90m[23m, Fe [3m[90m&lt;dbl&gt;[90m[23m, Ni [3m[90m&lt;dbl&gt;[90m[23m, Cu [3m[90m&lt;dbl&gt;[90m[23m, Zn [3m[90m&lt;dbl&gt;[90m[23m, Ga [3m[90m&lt;dbl&gt;[90m[23m, Ge [3m[90m&lt;dbl&gt;[90m[23m,[39m ## [90m# Br [3m[90m&lt;dbl&gt;[90m[23m, Rb [3m[90m&lt;dbl&gt;[90m[23m, Sr [3m[90m&lt;dbl&gt;[90m[23m, Y [3m[90m&lt;dbl&gt;[90m[23m, Zr [3m[90m&lt;dbl&gt;[90m[23m, Pd [3m[90m&lt;dbl&gt;[90m[23m, Cd [3m[90m&lt;dbl&gt;[90m[23m,[39m ## [90m# I [3m[90m&lt;dbl&gt;[90m[23m, Cs [3m[90m&lt;dbl&gt;[90m[23m, Ba [3m[90m&lt;dbl&gt;[90m[23m, Nd [3m[90m&lt;dbl&gt;[90m[23m, Sm [3m[90m&lt;dbl&gt;[90m[23m, Yb [3m[90m&lt;dbl&gt;[90m[23m, Ta [3m[90m&lt;dbl&gt;[90m[23m,[39m ## [90m# W [3m[90m&lt;dbl&gt;[90m[23m, Pb [3m[90m&lt;dbl&gt;[90m[23m, Bi [3m[90m&lt;dbl&gt;[90m[23m, `Mo inc` [3m[90m&lt;dbl&gt;[90m[23m, `Mo coh` [3m[90m&lt;dbl&gt;[90m[23m,[39m ## [90m# filename [3m[90m&lt;chr&gt;[90m[23m, position [3m[90m&lt;dbl&gt;[90m[23m, `sample surface` [3m[90m&lt;dbl&gt;[90m[23m, `E-gain` [3m[90m&lt;dbl&gt;[90m[23m,[39m ## [90m# `E-offset` [3m[90m&lt;dbl&gt;[90m[23m, `F-slope` [3m[90m&lt;dbl&gt;[90m[23m, `F-offset` [3m[90m&lt;dbl&gt;[90m[23m, `Fe a*2` [3m[90m&lt;dbl&gt;[90m[23m, `Fe[39m ## [90m# a+b` [3m[90m&lt;dbl&gt;[90m[23m, S1 [3m[90m&lt;dbl&gt;[90m[23m, S2 [3m[90m&lt;dbl&gt;[90m[23m, S3 [3m[90m&lt;dbl&gt;[90m[23m, Dt [3m[90m&lt;dbl&gt;[90m[23m, label [3m[90m&lt;chr&gt;[90m[23m[39m "],["preparing-data-for-multivariate-data-analysis.html", "5.2 Preparing Data for Multivariate Data Analysis", " 5.2 Preparing Data for Multivariate Data Analysis Where multivariate methods (cluster analysis, principle components analysis, correlation matrices) are required, it is usually necessary to transform data. This is because the statistical assumptions that underlie these methods are often not met when dealing with compositional data like that from an XRF core-scanner. There is no “right” or ideal way to deal with these issues, but a common method is to use a form of log transformation. Here we use a centred log transformation, which cannot be performed on zero values. df %&gt;% chemometrics::clr(df) There are a number of possible solutions to this problem of zero values, none ideal, but the most common are to add an arbitrary number to the entirety of the data, or to replace zero values with a very small number, perhaps the limit of precision or the limit of detection. In the example shown, the limit of precision for the peak area intensity or counts is used (0.001 or 1 respectively). input[input == 0] &lt;- 0.001 A final solution may be to exclude zero values from any subsequent analysis, although not all methods tolerate NA in the data. Where there are many zero values for a particular variable, the variable may not provide good data and could be excluded. df %&gt;% na_if(0) In most multivariate analyses there are a number of variables which have high signal-to-noise ratios or otherwise only add noise to multivariate methods. In these cases, they might be excluded from multivariate methods. The selection of variables for inclusion is a matter for the analyst. It goes without saying that variables that are not part of the composition (that is, anything that is not an element) must be removed from the data used for multivariate analysis. df %&gt;% select(-any_of(c(&quot;Mg&quot;, &quot;Co&quot;, &quot;Mo&quot;)) Finally, in order to correctly identify the measurements to their original data source, it is necessary to use row names that uniquely identify observations. For single scans this is not usually an issue — the depth or position variable can be used. However, where a dataset is a composition of multiple cores, you may find that there are multiple observations for a particular depth where cores overlap. In the example shown we create a unique name for each observation by concatenating the name of the core as recorded in the label column of a core sequence joined using itraxR::itrax_join() with the corresponding depth variable, but the code could be modified to suit a different work flow. rowlabels &lt;- str_c(df$label, df$depth, sep = &quot;_&quot;) input &lt;- df %&gt;% select(any_of(elements)) input &lt;- input %&gt;% select(-any_of(c(&quot;Mg&quot;, &quot;Co&quot;, &quot;Mo&quot;))) input[input == 0] &lt;- 0.001 library(chemometrics) input &lt;- clr(input) row.names(input) &lt;- rowlabels "],["multivariate-methods.html", "Chapter 6 Multivariate Methods", " Chapter 6 Multivariate Methods Input data often needs extensive preparation if useful results are to be obtained — transformation, dealing with zero values, and NA values. It is worth mentioning some general issues around the robustness of multivariate analysis. "],["correlation-coefficients.html", "6.1 Correlation Coefficients", " 6.1 Correlation Coefficients The Pearson’s R correlation coefficient is occasionally used to study the relationships between individual elements. "],["unconstrained-cluster-analysis.html", "6.2 Unconstrained Cluster Analysis", " 6.2 Unconstrained Cluster Analysis "],["constrained-cluster-analaysis.html", "6.3 Constrained Cluster Analaysis", " 6.3 Constrained Cluster Analaysis "],["principle-components-analysis.html", "6.4 Principle Components Analysis", " 6.4 Principle Components Analysis "],["calibrating-data.html", "Chapter 7 Calibrating Data ", " Chapter 7 Calibrating Data "],["suitable-methods.html", "7.1 Suitable Methods", " 7.1 Suitable Methods "],["linear-methods.html", "7.2 Linear Methods", " 7.2 Linear Methods "],["log-ratio-methods.html", "7.3 Log-Ratio Methods", " 7.3 Log-Ratio Methods "],["exporting-data.html", "Chapter 8 Exporting Data", " Chapter 8 Exporting Data Data is easy to export from R. Tables can be exported by piping to readr::write_csv(). For diagrams created in ggplot2, pipe to ggsave(). Sometimes it is necessary to reduce the resolution of Itrax XRF data, usually to facilitate direct comparison with some other lower resolution data. For example, if calibrating using ICP-MS sub-samples taken at 10 mm intervals, but the Itrax XRF scan is at 0.2 mm, it will be necessary to average 50 Itrax measurements for each ICP-MS measurement. This is facilitated using the itrax_averaging() function. Despite the name, the function can use any appropriate summary function (e.g. standard deviation sd() or median median().) # get the Ti mean and standard deviation in 10 mm intervals head(data.frame(depthmin = itrax_averaging(CD166_19_xrf, 10)$depthmin, depthmax = itrax_averaging(CD166_19_xrf, 10)$depthmax, Ti_mean = itrax_averaging(CD166_19_xrf, 10)$Ti, Ti_sd = itrax_averaging(CD166_19_xrf, 10, fun = sd)$Ti)) ## depthmin depthmax Ti_mean Ti_sd ## 1 1 10 2101.3 331.36789 ## 2 11 20 2460.8 306.68833 ## 3 21 30 2222.5 50.31733 ## 4 31 40 2264.9 118.89253 ## 5 41 50 2311.8 163.99377 ## 6 51 60 2401.3 90.61770 "],["references.html", "References", " References "]]
