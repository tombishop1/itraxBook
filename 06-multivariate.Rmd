# Multivariate Methods

## Preparing Data for Multivariate Data Analysis
Where multivariate methods (cluster analysis, principal components analysis, correlation matrices) are required, it is usually necessary to transform data and treat them in a special way to avoid breaking the assumptions of a method or drawing erroneous conclusions. This is because the constant sum constraint that defines compositional data - put simply, if one element increases in proportion, an equal decrease must occur in the remaining elements that make up the composition. This is further complicated by unobserved elements, dimensionless (i.e. calibrated) data, and observations below the limit of detection. The package `compositions` deals with much of these issues, including any necessary transformation, and ensures that the data are treated differently by functions like `princomp()` and `dist()`, e.g. `compositions::princomp.acomp()` by setting a `class` attribute and providing modified functions. 

It's worth spending some time getting familiar with the documentation for `compositions`, and possibly the wider literature around compositional data analysis. Several different methods are provided depending on the nature of the compositional data - in these examples, we use the `acomp()` but other methods are available. This package also deals with the variety of different types of zero and missing values. For these count data we deal with values that are below the limit of detection by letting the `compositions` package know the detection limit. For these count data, the detection limit is `1`, and thus is coded as `-1`. This allows `zeroreplace()` to correctly deal with this problem. 

In order to correctly identify the observations to their original data source, it is necessary to use row names that uniquely identify observations. For single scans this is not usually an issue --- the `depth` or `position` variable can be used. However, where a dataset is a composition of multiple cores, you may find that there are multiple observations for a particular depth where cores overlap. We don't usually use row names when working in the `tidyverse` style, but because were going to be using base functions like `princomp()` and `dist()`, they may become necessary. Here we create a unique identifier in `CD166_19_xrf` called `uid` that we will use to uniquely identify observations throughout the rest of our analysis. 

```{r uid}
CD166_19_xrf <- CD166_19_xrf %>%
  mutate(uid = paste0(label, "_", depth))

TRUE %in% CD166_19_xrf$uid %>% duplicated()
```

```{r message=FALSE, warning=FALSE}
CD166_19_xrf_acomp <- CD166_19_xrf %>%
  filter(qc == TRUE) %>%
  select(any_of(c(elementsList, "uid"))) %>%
  column_to_rownames("uid") %>%
  mutate(across(everything(), function(x){ifelse(x == 0, -1, x)})) %>%
  acomp()
head(CD166_19_xrf_acomp)
```
Where it is necessary to keep some (or all) of the other information, this can be re-joined to the `acomp()` object, but only if its `acomp` class is removed. For example:

```{r}
CD166_19_xrf_acomp_meta <- full_join(CD166_19_xrf_acomp %>% 
                                       as.data.frame() %>%
                                       rownames_to_column("uid"),
                                     CD166_19_xrf %>%
                                       select(-any_of(elementsList)),
                                     by = "uid"
                                     ) %>%
  arrange(depth, label) 
```

## Principal Component Analysis

Principal component analysis (PCA) is a common method for exploring multivariate data. Note the use of `zeroreplace()` - this is because the `princomp()` method defined for th `acomp` class uses a centred-log-ratio (`clr()`) transformation that is intolerant to zero-values. 

```{r}
CD166_19_xrf_acomp %>%
  zeroreplace() %>%
  princomp() %>%
  biplot(xlabs = rep(".",times = nrow(CD166_19_xrf_acomp)))
```

It is useful to plot components over depth. They can be extracted and plotted as follows:

```{r}
bind_rows(
  tibble(depth = CD166_19_xrf %>%
           filter(qc == FALSE) %>%
           pull("depth"),
         Comp.1 = NA
        ),

  tibble(
    depth = CD166_19_xrf %>%
      filter(qc == TRUE) %>%
      pull("depth"),
    Comp.1 = CD166_19_xrf_acomp %>%
      zeroreplace() %>%
      princomp() %>%
      magrittr::extract2("scores") %>%
      as_tibble() %>%
      pull("Comp.1")
    )) %>%
  
  arrange(depth) %>%
  
  ggplot(aes(x = depth, y = Comp.1)) +
  geom_line() + 
  scale_x_reverse(name = "depth [mm]")
```

## Using `ordr` for PCA

The `ordr` package can be used to retain metadata (depths, labels, groups etc.) along with the PCA object. This is particularly useful for complex biplots using `ggplot2`. The following example uses the `CD166_19_xrf_acomp_meta` from the previous section; note that `myElements` is a vector of elements to include in the ordination, in this case generated in the section [Noisy Data]. 

```{r}
CD166_19_xrf_acomp_meta %>%
    ordr::ordinate(., cols = any_of(myElements),
                   model = ~ princomp(clr(.)),
                   augment = any_of(c("depth", "label"))
                   ) %>%
  
  ordr::ggbiplot(., sec.axes = "cols", scale.factor = 8) +
  ordr::geom_rows_point(aes(colour = depth, shape = label), alpha = 0.5) +
  ordr::geom_cols_vector() +
  ordr::geom_cols_text_radiate(aes(label = name)) +
  scale_color_continuous(type = "viridis", trans = "reverse")
```

## Unconstrained Cluster Analysis
Unconstrained cluster analysis will group each measurement by similarity, returning an arbitrary number of groups as defined by the function. This is useful in identifying recurring compositional units, or identifying candidate samples for quantitative analysis. 

```{r unconstrained_clusters}
left_join(CD166_19_xrf, 
          tibble(uid = CD166_19_xrf_acomp %>%
                   rownames(),
                 group = dist(CD166_19_xrf_acomp) %>%
                     hclust(method = "ward.D2") %>%
                     cutree(k = 5) %>%
                     as.factor()
                 ),
          by = "uid"
) %>%
  
  ggplot() + 
  geom_tile(aes(x = depth, y = 1, fill = group)) +
  scale_x_reverse() +
  theme(axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank())
```

## Constrained Cluster Analysis

Constrained cluster analysis is helpful in identifying units of deposition in the sedimentary sequence. It forces each sample to remain in sequence, thus there are no recurring units along the stratigraphy. 

```{r constrained_clusters_1}
bind_rows(tibble(depth = filter(CD166_19_xrf, qc == TRUE) %>% pull(depth),
                 group = rioja::chclust(dist(CD166_19_xrf_acomp)) %>%
                 cutree(k = 5) %>%
                 as.factor()), 
          
          CD166_19_xrf %>%
            filter(qc == FALSE) %>%
            mutate(group = NA) %>%
            select(depth, group)) %>%
  arrange(depth) %>%
  
  ggplot() + 
  geom_tile(aes(x = depth, y = 1, fill = group)) +
  scale_x_reverse() +
  theme(axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank())
```
